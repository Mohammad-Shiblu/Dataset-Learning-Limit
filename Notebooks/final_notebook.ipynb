{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous case ambiguity and error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Continuous case ambiguity \n",
    "# Function for ambiguity calculation\n",
    "def calculate_continuous_case_ambiguity(df, class_column):\n",
    "    features = df.columns.drop(class_column)\n",
    "    classes = df[class_column].unique()\n",
    "\n",
    "    # Step 1: Calculate Hypercubes\n",
    "    grouped = df.groupby(class_column)[features]\n",
    "    min_values = grouped.min()\n",
    "    max_values = grouped.max()\n",
    "    hypercubes = {cls: (min_values.loc[cls].values, max_values.loc[cls].values) for cls in classes}\n",
    "\n",
    "    # Step 2: Calculate Overlap Regions\n",
    "    overlap_regions = []\n",
    "    class_list = list(hypercubes.keys())\n",
    "    num_classes = len(class_list)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        for j in range(i + 1, num_classes):\n",
    "            min_overlap = np.maximum(hypercubes[class_list[i]][0], hypercubes[class_list[j]][0])\n",
    "            max_overlap = np.minimum(hypercubes[class_list[i]][1], hypercubes[class_list[j]][1])\n",
    "            if np.all(min_overlap <= max_overlap):\n",
    "                overlap_regions.append((class_list[i], class_list[j], min_overlap, max_overlap))\n",
    "\n",
    "    # Step 3: Count Samples in Overlap Regions\n",
    "    samples = df[features].values\n",
    "    class_labels = df[class_column].values\n",
    "\n",
    "    samples_in_overlap = {}\n",
    "\n",
    "    for cls1, cls2, min_overlap, max_overlap in overlap_regions:\n",
    "        in_overlap_cls1 = np.all((samples >= min_overlap) & (samples <= max_overlap), axis=1) & (class_labels == cls1)\n",
    "        in_overlap_cls2 = np.all((samples >= min_overlap) & (samples <= max_overlap), axis=1) & (class_labels == cls2)\n",
    "\n",
    "        count_cls1 = np.sum(in_overlap_cls1)\n",
    "        count_cls2 = np.sum(in_overlap_cls2)\n",
    "\n",
    "        region_key = f'{cls1}-{cls2}'\n",
    "        samples_in_overlap[region_key] = {cls1: count_cls1, cls2: count_cls2}\n",
    "\n",
    "    # Step 4: Calculate Ambiguity\n",
    "    total_samples_per_class = df[class_column].value_counts().to_dict()\n",
    "    print(\"total samples per class:\")\n",
    "    print(total_samples_per_class)\n",
    "    ambiguity_values = {cls: 0 for cls in classes}\n",
    "\n",
    "    for region, counts in samples_in_overlap.items():\n",
    "        cls1, cls2 = region.split('-')\n",
    "        cls1 = float(cls1)  # Ensure class labels are correctly interpreted\n",
    "        cls2 = float(cls2)\n",
    "        if cls1 in total_samples_per_class and cls2 in total_samples_per_class:\n",
    "            if total_samples_per_class[cls1] > 0:\n",
    "                ambiguity_values[cls1] += counts[cls1] / total_samples_per_class[cls1]\n",
    "            if total_samples_per_class[cls2] > 0:\n",
    "                ambiguity_values[cls2] += counts[cls2] / total_samples_per_class[cls2]\n",
    "\n",
    "    mean_ambiguity = np.mean(list(ambiguity_values.values())) if ambiguity_values else 0.0\n",
    "\n",
    "    return mean_ambiguity, overlap_regions, samples_in_overlap\n",
    "\n",
    "# function for error calculation\n",
    "def calculate_error_probability(df, feature_columns, label_column):\n",
    "    # Train the decision tree\n",
    "    X = df[feature_columns]\n",
    "    y = df[label_column]\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth=None)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    training_accuracy = clf.score(X, y)\n",
    "    print(f'Training Accuracy: {training_accuracy * 100:.2f}%')\n",
    "\n",
    "    # Function to extract rectangles and labels from a trained decision tree\n",
    "    def get_rectangles_from_tree(tree):\n",
    "        left = tree.children_left\n",
    "        right = tree.children_right\n",
    "        threshold = tree.threshold\n",
    "        feature = tree.feature\n",
    "        value = tree.value\n",
    "        \n",
    "        def recurse(node, bounds):\n",
    "            if feature[node] == _tree.TREE_UNDEFINED:\n",
    "                # It's a leaf node\n",
    "                leaf_label = np.argmax(value[node][0])\n",
    "                return [(bounds, leaf_label)]\n",
    "            \n",
    "            new_bounds_left = [list(b) for b in bounds]\n",
    "            new_bounds_right = [list(b) for b in bounds]\n",
    "            \n",
    "            feature_index = feature[node]\n",
    "            threshold_value = threshold[node]\n",
    "            \n",
    "            new_bounds_left[feature_index][1] = threshold_value\n",
    "            new_bounds_right[feature_index][0] = threshold_value\n",
    "            \n",
    "            left_rectangles = recurse(left[node], new_bounds_left)\n",
    "            right_rectangles = recurse(right[node], new_bounds_right)\n",
    "            \n",
    "            return left_rectangles + right_rectangles\n",
    "\n",
    "        # Initialize bounds for each feature\n",
    "        initial_bounds = [[-np.inf, np.inf] for _ in range(tree.n_features)]\n",
    "        rectangles = recurse(0, initial_bounds)\n",
    "        return rectangles\n",
    "\n",
    "    # Extract rectangles and labels from the decision tree\n",
    "    rectangles = get_rectangles_from_tree(clf.tree_)\n",
    "\n",
    "    # Calculate KDE for each class\n",
    "    class_0_data = df[df[label_column] == 0][feature_columns]\n",
    "    class_1_data = df[df[label_column] == 1][feature_columns]\n",
    "\n",
    "    kde_class_0 = stats.gaussian_kde(class_0_data.T)\n",
    "    kde_class_1 = stats.gaussian_kde(class_1_data.T)\n",
    "\n",
    "    # Calculate probabilities for the segments\n",
    "    segment_probabilities = []\n",
    "    for rect, label in rectangles:\n",
    "        bounds_min = [b[0] for b in rect]\n",
    "        bounds_max = [b[1] for b in rect]\n",
    "        segment = df[np.all((df[feature_columns] >= bounds_min) & (df[feature_columns] < bounds_max), axis=1)]\n",
    "        if not segment.empty:\n",
    "            actual_value = segment[label_column].iloc[0]\n",
    "            if actual_value == 0.0:\n",
    "                segment_probabilities.append(kde_class_1.integrate_box(bounds_min, bounds_max, maxpts=200000))\n",
    "            else:\n",
    "                segment_probabilities.append(kde_class_0.integrate_box(bounds_min, bounds_max, maxpts=200000))\n",
    "\n",
    "    # Compute total error probability\n",
    "    total_error_probability_all_segments = np.sum(segment_probabilities)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return total_error_probability_all_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete case ambiguity and error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for discrete case ambiguity \n",
    "def calculate_discrete_ambiguity(df, feature_columns, class_column):\n",
    "    \n",
    "    d = df[class_column].nunique()\n",
    "    # combinaion generators\n",
    "    df[\"feature_combination\"] = df[feature_columns].astype(str).agg('_'.join, axis=1)\n",
    "    \n",
    "    # total no of combinations\n",
    "    combination_counts = df.groupby(['feature_combination', class_column]).size().reset_index(name='count')\n",
    "    \n",
    "    # no of combination\n",
    "    total_combination_counts = df['feature_combination'].value_counts().reset_index(name='total_count').rename(columns={'index': 'feature_combination'})\n",
    "    \n",
    "    combination_probs = pd.merge(combination_counts, total_combination_counts, on='feature_combination')\n",
    "    combination_probs['probability'] = combination_probs['count'] / combination_probs['total_count']\n",
    "    \n",
    "    \n",
    "    combination_probs_pivot = combination_probs.pivot(index='feature_combination', columns=class_column, values='probability').fillna(0)\n",
    "    combination_probs_pivot.columns = [f'P(class={int(col)})' for col in combination_probs_pivot.columns]\n",
    "    \n",
    "    df = pd.merge(df, combination_probs, on=['feature_combination', class_column], how='left')\n",
    "\n",
    "    ambiguity = ((1-combination_probs_pivot.max(axis=1))*(d/(d-1))).mean() # d\n",
    "    \n",
    "    return ambiguity, df, combination_probs_pivot\n",
    "\n",
    "\n",
    "def calculate_discrete_classification_error(data):\n",
    "    # Calculate P(C_j), the prior probability of class j\n",
    "    def prior_probability(cls):\n",
    "        return len(data[data['class'] == cls]) / len(data)\n",
    "    \n",
    "    def likelihood(sample, cls):\n",
    "        feature_match_data = data.copy()\n",
    "        \n",
    "        # Loop over all features (excluding the 'class' column)\n",
    "        for feature in sample.index[:-1]:\n",
    "            feature_value = sample[feature]\n",
    "            # Filter the data to match the current feature value\n",
    "            feature_match_data = feature_match_data[feature_match_data[feature] == feature_value]\n",
    "        \n",
    "        # Filter the dataset to include only rows with the same class as 'cls'\n",
    "        class_feature_match_data = feature_match_data[feature_match_data['class'] == cls]\n",
    "        \n",
    "        # Calculate the likelihood as the proportion of this feature combination that belongs to the specified class\n",
    "        if len(feature_match_data) == 0:\n",
    "            return 0  # Avoid division by zero if feature combination doesn't exist in the dataset\n",
    "        probability = len(class_feature_match_data) / len(feature_match_data)\n",
    "        return 1-probability\n",
    "\n",
    "    # Calculate the overall discrete classification error\n",
    "    total_error = 0\n",
    "    \n",
    "    for i in data.itertuples(index=False):\n",
    "        sample = pd.Series(i, index=data.columns)\n",
    "        true_class = sample['class']\n",
    "        prior_true_class = prior_probability(true_class)\n",
    "        \n",
    "        # Sum the error contributions from misclassification to all other classes\n",
    "        for other_class in data['class'].unique():\n",
    "            if other_class != true_class:\n",
    "                error_component = likelihood(sample, true_class) * prior_true_class\n",
    "                total_error += error_component\n",
    "    \n",
    "    # Normalize by the number of samples\n",
    "    normalized_error = total_error / len(data)\n",
    "    return normalized_error\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
